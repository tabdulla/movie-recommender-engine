{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial for recommender engine usingCollaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it uses python 3.5.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.6 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing needed packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "from time import time\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset info\n",
    "    .Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.\n",
    "    .Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('datasets'):\n",
    "    os.makedirs('datasets')\n",
    "cwd = os.getcwd()\n",
    "datasets_path = os.path.join(cwd, 'datasets')\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset\n",
    "    . small dataset size = 955 kb \n",
    "    . complete dataset size = 264 mb\n",
    "   in this tutorial we will use the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_f = urllib.request.urlretrieve(small_dataset_url,small_dataset_path)\n",
    "# complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "# with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "#     z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intializing spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "   .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "   .appName(\"Recommender-system\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "sc =  spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data set \n",
    "this tables we will use from dataset\n",
    "\n",
    "Each line in the ratings dataset (ratings.csv) is formatted as: userId,movieId,rating,timestamp\n",
    "\n",
    "Each line in the movies (movies.csv) dataset is formatted as: movieId,title,genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ratings.csv path \n",
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "# load ratings.csv file to rdd \n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "# find ratings.csv header\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing and removing irrelevant data from rating.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file to rdd and removing header from it and removing timestamp from each row \n",
    "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring that data loaded correctly \n",
    "    RDD format -> ('user_id','movie_id','actual rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load movies.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding movies.csv file \n",
    "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "# load movies.csv file to rdd\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "# find rating .csv header \n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing and removing irrelevant data from movies.csv to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file to rdd and removing header and genere from it \n",
    "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring that movies.cs file is loaded correctly \n",
    "    RDD formate -> ('movie_id','movie_name(production_year)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and spliting  dataset  to rdds \n",
    "    split dataset into\n",
    "        . Traning dataset = 60%\n",
    "        . Validation dataset = 20%\n",
    "        . Test Dataset = 20%\n",
    "note that we removed actual ratings from testing and validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data randomly to training, validation and test data sets with ratio 60-20-20\n",
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "# remove actual user rating from validation dataset\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "# remove actual user rating from testing dataset\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring and tunning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.9190356728088455\n",
      "For rank 8 the RMSE is 0.9187811173021727\n",
      "For rank 10 the RMSE is 0.9162188124353527\n",
      "The best model was trained with rank 10\n"
     ]
    }
   ],
   "source": [
    "# seed is used for reproducability \n",
    "seed = 5\n",
    "iterations = 10\n",
    "# is used to avoid over and under fitting \n",
    "regularization_parameter = 0.1\n",
    "tolerance = 0.02\n",
    "ranks = [4, 8, 10]\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_model = None\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    \n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    print ('For rank {} the RMSE is {}'.format(rank, error))\n",
    "    \n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "        best_model = model\n",
    "        \n",
    "print ('The best model was trained with rank {}'.format(best_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the BEST model for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join('/home/tabdalla/Development/code/col-filtering_recommender-system', 'models', 'movie_lens_als_2')\n",
    "# best_model.save(sc, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join('/home/tabdalla/Development/code/col-filtering_recommender-system', 'models', 'movie_lens_als_2')\n",
    "# loaded_model = MatrixFactorizationModel.load(sc, model_path)\n",
    "# predictions = loaded_model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# predictions.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See predected results\n",
    "    RDD format ((user_id,movie_is),predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((599, 45208), 1.5325057468429124),\n",
       " ((368, 3272), 2.6486584653325935),\n",
       " ((603, 3272), 3.038943126586739),\n",
       " ((182, 3272), 2.654129777267586),\n",
       " ((560, 52328), 3.1635993554993203)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare between predicted result and actual result in dataset\n",
    "    RDD format ((user_id,movie_id),(actual_rating,predected_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((140, 4322), (4.0, 3.274917309363992)),\n",
       " ((462, 148626), (3.5, 2.919451170962174)),\n",
       " ((427, 555), (4.5, 3.542172834664159)),\n",
       " ((279, 115569), (4.5, 3.786988737089138)),\n",
       " ((455, 539), (4.0, 3.602474727748841))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9172323011798893\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is {}'.format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the  model using the complete dataset instead of small data set\n",
    "  in order to get better results we shall use the complete dataset but here we used the small one due to memory limitation \n",
    "  all we need to change 'ml-latest-small' -> 'ml-latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset file\n",
    "## TAKE CARE HERE WE CHANGED USAGE OF COMPLETE PATH TO USE SMALL DUE TO MEMORY LIMITATION \n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and modify ratings.csv file and parse it to rdd \n",
    "modification here means convert string results to int as we did before for accurate computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100836 ratings in the small dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "    \n",
    "print (\"There are {} ratings in the small dataset\".format((complete_ratings_data.count())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using complete dataset with chosen parameters\n",
    "here we did't need validation dataset we need only test to find the error of our model so we splited our dataset to \n",
    "    Training -> 70%\n",
    "    test -> 30% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to training and testing data sets with ration 70% - 30%  \n",
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using testing dataset to calculate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.897018309116098\n"
     ]
    }
   ],
   "source": [
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print ('For testing data the RMSE is {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#   HERE ALSO I CHANGED THE USAGE OF COMPLETE DATASET TO SMALL ONE DUE TO MEMORY LIMITATOIN    #\n",
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing movies.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9742movies in the complete dataset \n"
     ]
    }
   ],
   "source": [
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    \n",
    "print (\"There are {}movies in the complete dataset \".format(complete_movies_titles.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate average rating for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new user to use it in our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 2), (0, 25, 3), (0, 32, 4), (0, 335, 4), (0, 379, 3), (0, 296, 2), (0, 858, 5), (0, 50, 3)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 1\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,4), # Star Wars (1977)\n",
    "     (0,1,3), # Toy Story (1995)\n",
    "     (0,16,2), # Casino (1995)\n",
    "     (0,25,3), # Leaving Las Vegas (1995)\n",
    "     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (0,335,4), # Flintstones, The (1994)\n",
    "     (0,379,3), # Timecop (1994)\n",
    "     (0,296,2), # Pulp Fiction (1994)\n",
    "     (0,858,5) , # Godfather, The (1972)\n",
    "     (0,50,3) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print ('New user ratings: {}'.format(new_user_ratings_RDD.take(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join new user rdd with oold one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train new ALS Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 1.611 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict ratings for user id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings)\n",
    "\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2052, ((3.3494157407042504, 'Hocus Pocus (1993)'), 23)),\n",
       " (80880, ((3.9365597171089948, 'Stone (2010)'), 2)),\n",
       " (4104, ((1.4549844191723624, 'Ernest Goes to Camp (1987)'), 5))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New user recommendation RDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top rated movies with more than 25 ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 25 reviews):\n",
      "('\"Shawshank Redemption', 5.285185716267375, 317)\n",
      "('\"Grand Day Out with Wallace and Gromit', 5.223192281612513, 28)\n",
      "('Harold and Maude (1971)', 5.19906152114903, 26)\n",
      "('Star Wars: Episode V - The Empire Strikes Back (1980)', 5.133441825730453, 211)\n",
      "(\"Rosemary's Baby (1968)\", 5.105022183979428, 32)\n",
      "('\"Great Escape', 5.0930324621117276, 43)\n",
      "('\"Philadelphia Story', 5.075125732289349, 29)\n",
      "('Star Wars: Episode IV - A New Hope (1977)', 5.061964838059363, 251)\n",
      "(\"Schindler's List (1993)\", 5.060758112073332, 220)\n",
      "('\"Princess Bride', 5.05355591202288, 142)\n",
      "('Wallace & Gromit: The Best of Aardman Animation (1996)', 5.045302936015783, 27)\n",
      "('Wallace & Gromit: The Wrong Trousers (1993)', 5.032148118594586, 56)\n",
      "('Forrest Gump (1994)', 5.030008197569898, 329)\n",
      "('\"Godfather: Part II', 5.008653445361541, 129)\n",
      "('American History X (1998)', 5.005440471513096, 129)\n",
      "(\"One Flew Over the Cuckoo's Nest (1975)\", 5.004983065406305, 133)\n",
      "('Fight Club (1999)', 5.0027388173384715, 218)\n",
      "('Life Is Beautiful (La Vita è bella) (1997)', 4.9984377455944395, 88)\n",
      "('Monty Python and the Holy Grail (1975)', 4.996559506262689, 136)\n",
      "('Whiplash (2014)', 4.990536398652333, 38)\n",
      "('Adaptation (2002)', 4.9865364559606515, 46)\n",
      "('Roman Holiday (1953)', 4.985221703451098, 26)\n",
      "('\"Godfather', 4.983869670494391, 192)\n",
      "('Star Wars: Episode VI - Return of the Jedi (1983)', 4.983192285996131, 196)\n",
      "('Blade Runner (1982)', 4.982218269239639, 124)\n"
     ]
    }
   ],
   "source": [
    "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict rating for user ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=45208, rating=2.349938151874632)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = os.path.join(cwd, 'models', 'movie_lens_als')\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
