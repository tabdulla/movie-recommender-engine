{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tutorial for recommender engine usingCollaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it uses python version 3.5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.6 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from time import time\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "####              UNUSED IMPORTS             ####\n",
    "#################################################\n",
    "# from pandas import Series, DataFrame\n",
    "# import pandas as pd\n",
    "# import math\n",
    "# from pyspark.sql.functions import udf, lit\n",
    "# from pyspark.sql.types import  BooleanType, StringType\n",
    "# import pyspark\n",
    "# from pyspark import SparkConf\n",
    "# from pyspark.mllib.recommendation import ALS\n",
    "# from pyspark.sql import Row\n",
    "# from pyspark.mllib.recommendation import MatrixFactorizationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "#     .Small: 100,000 ratings and 2,488 tag applications applied to 8,570 movies by 706 users. Last updated 4/2015.\n",
    "#     .Full: 21,000,000 ratings and 470,000 tag applications applied to 27,000 movies by 230,000 users. Last updated 4/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('datasets'):\n",
    "    os.makedirs('datasets')\n",
    "cwd = os.getcwd()\n",
    "datasets_path = os.path.join(cwd, 'datasets')\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "#     . small dataset size = 955 kb \n",
    "#     . complete dataset size = 264 mb\n",
    "#    in this tutorial we will use the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(small_dataset_path):\n",
    "    small_f = urllib.request.urlretrieve(small_dataset_url,small_dataset_path)\n",
    "# complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "# with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "#     z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intializing spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "   .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "   .appName(\"Recommender-system\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "sc =  spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set \n",
    "# this tables we will use from dataset\n",
    "\n",
    "# Each line in the ratings dataset (ratings.csv) is formatted as: userId,movieId,rating,timestamp\n",
    "\n",
    "# Each line in the movies (movies.csv) dataset is formatted as: movieId,title,genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ratings.csv path \n",
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "# load ratings.csv file to dataframe and drop timespamp column \n",
    "rating_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(small_ratings_file).drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensuring that rating dataframe is loaded correctly \n",
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting rating dataframe coloumns to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casting userId to int\n",
    "rating_df = rating_df.withColumn('userId', rating_df['userId'].cast(IntegerType()))\n",
    "# casting movieId to int \n",
    "rating_df = rating_df.withColumn('movieId', rating_df['movieId'].cast(IntegerType()))\n",
    "#casting rating to float \n",
    "rating_df = rating_df.withColumn('rating', rating_df['rating'].cast(FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print schema of rating dataframe \n",
    "rating_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movies.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding movies.csv file \n",
    "movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "# load movies.csv file to dataframe and drop genres column \n",
    "movies_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(movies_file).drop('genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|      Jumanji (1995)|\n",
      "|      3|Grumpier Old Men ...|\n",
      "|      4|Waiting to Exhale...|\n",
      "|      5|Father of the Bri...|\n",
      "|      6|         Heat (1995)|\n",
      "|      7|      Sabrina (1995)|\n",
      "|      8| Tom and Huck (1995)|\n",
      "|      9| Sudden Death (1995)|\n",
      "|     10|    GoldenEye (1995)|\n",
      "|     11|American Presiden...|\n",
      "|     12|Dracula: Dead and...|\n",
      "|     13|        Balto (1995)|\n",
      "|     14|        Nixon (1995)|\n",
      "|     15|Cutthroat Island ...|\n",
      "|     16|       Casino (1995)|\n",
      "|     17|Sense and Sensibi...|\n",
      "|     18|   Four Rooms (1995)|\n",
      "|     19|Ace Ventura: When...|\n",
      "|     20|  Money Train (1995)|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ensuring that movies dataframe is loaded correctly\n",
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casting movies dataframe to int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.withColumn('movieId' ,movies_df['movieId'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print movies_df schema \n",
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing and spliting  dataset  to rdds \n",
    "#     split dataset into\n",
    "#         . Traning dataset = 60%\n",
    "#         . Validation dataset = 20%\n",
    "#         . Test Dataset = 20%\n",
    "# note that we removed actual ratings from testing and validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df,test_df = rating_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring and tunning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "\n",
    "param_grid = ParamGridBuilder().addGrid(\n",
    "    als.rank,\n",
    "    [10, 15],\n",
    ").addGrid(\n",
    "    als.maxIter,\n",
    "    [10, 15],\n",
    ").addGrid(\n",
    "    als.regParam,\n",
    "    [0.1,0.01,0.2],\n",
    ").build()\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    ")\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "\n",
    "\n",
    "model = tvs.fit(training_df)\n",
    "\n",
    "bestmodel=model.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rank=bestmodel.rank\n",
    "best_regParm=bestmodel._java_obj.parent().getRegParam()\n",
    "best_iterations=bestmodel._java_obj.parent().getMaxIter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the BEST model for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    91|    471|   1.0| 3.1514268|\n",
      "|   409|    471|   3.0| 3.3944638|\n",
      "|   372|    471|   3.0| 3.1064243|\n",
      "|   599|    471|   2.5| 2.8177652|\n",
      "|   603|    471|   4.0| 3.2178159|\n",
      "|   474|    471|   3.0|  3.315065|\n",
      "|   462|    471|   2.5| 2.9463058|\n",
      "|   217|    471|   2.0| 2.7720299|\n",
      "|   520|    471|   5.0| 3.6111546|\n",
      "|   136|    471|   4.0| 3.6572232|\n",
      "|   609|    833|   3.0|  1.665521|\n",
      "|    20|   1088|   4.5| 3.4505277|\n",
      "|   169|   1088|   4.5| 4.0843716|\n",
      "|   563|   1088|   4.0| 3.2047427|\n",
      "|   555|   1088|   4.0| 3.4016178|\n",
      "|   221|   1088|   3.0| 3.1049845|\n",
      "|    68|   1088|   3.5| 3.0921006|\n",
      "|   600|   1088|   3.5| 2.4753342|\n",
      "|   517|   1088|   1.0|  2.470663|\n",
      "|    19|   1238|   3.0| 3.1355453|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= bestmodel.transform(test_df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "error = evaluator.evaluate(predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.877753701089013\n"
     ]
    }
   ],
   "source": [
    "# printing ther error of our model\n",
    "print ('For testing data the RMSE is {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###             BUILDING MODEL USING COMPLETE DATASET                       ####\n",
    "################################################################################\n",
    "#N.B -> here we alos using the small one beacuse of memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset file\n",
    "############################################################################################\n",
    "## TAKE CARE HERE WE CHANGED USAGE OF COMPLETE PATH TO USE SMALL DUE TO MEMORY LIMITATION ##\n",
    "#############################################################################################\n",
    "complete_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100836 ratings in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# load ratings file to dataframe and removing timestamp column \n",
    "complete_ratings_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(complete_ratings_file).drop('timestamp')\n",
    "# casting userId to int\n",
    "complete_ratings_df = complete_ratings_df.withColumn('userId', complete_ratings_df['userId'].cast(IntegerType()))\n",
    "# casting movieId to int \n",
    "complete_ratings_df = complete_ratings_df.withColumn('movieId', complete_ratings_df['movieId'].cast(IntegerType()))\n",
    "#casting rating to float \n",
    "complete_ratings_df = complete_ratings_df.withColumn('rating', complete_ratings_df['rating'].cast(FloatType()))\n",
    "    \n",
    "print (\"There are {} ratings in the complete dataset\".format((complete_ratings_df.count())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using complete dataset with chosen parameters\n",
    "\n",
    "# here we did't need validation dataset we need only test to find the error of our model so we splited our dataset to Training -> 70% test -> 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, test_df = complete_ratings_df.randomSplit([0.8,0.2])\n",
    "# building model\n",
    "als = ALS(maxIter=best_iterations, regParam=best_regParm,rank=best_rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "model = als.fit(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING MODEL ERROR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8893666775012877\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "error = evaluator.evaluate(predictions)\n",
    "\n",
    "print ('For testing data the RMSE is {}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###               RECOMMENDATION ENGINE STARTS HERE                         ####\n",
    "################################################################################\n",
    "#N.B -> here we alos using the small one beacuse of memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find movies.csv file location \n",
    "complete_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "#load movies.csv filt to dataframe and removing genres coloumn \n",
    "complete_movies_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(complete_movies_file).drop('genres')\n",
    "# casting movieId to integer \n",
    "complete_movies_df = complete_movies_df.withColumn('movieId' ,complete_movies_df['movieId'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9742 movies in the complete dataset \n"
     ]
    }
   ],
   "source": [
    "# counting movies \n",
    "print (\"There are {} movies in the complete dataset \".format(complete_movies_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID_with_avg_ratings_df=complete_ratings_df.groupby('movieId').agg({'rating':'avg'})\n",
    "movies_rating_counts_df=complete_ratings_df.groupby(\"movieId\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add New User to our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ID = 1\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (1,2,4), # Star Wars (1977)\n",
    "     (1,1,3), # Toy Story (1995)\n",
    "     (1,16,2), # Casino (1995)\n",
    "     (1,25,3), # Leaving Las Vegas (1995)\n",
    "     (1,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
    "     (1,335,4), # Flintstones, The (1994)\n",
    "     (1,379,3), # Timecop (1994)\n",
    "     (1,296,2), # Pulp Fiction (1994)\n",
    "     (1,858,5) , # Godfather, The (1972)\n",
    "     (1,50,3) # Usual Suspects, The (1995)\n",
    "    ]\n",
    "\n",
    "# creating new_user_rating dataframe\n",
    "new_user_ratings_df = spark.createDataFrame(new_user_ratings)\n",
    "\n",
    "#casting userId,MovieId, rating to their appropriate datatypes\n",
    "new_user_ratings_df = new_user_ratings_df.withColumn('userId', new_user_ratings_df[0].cast(IntegerType()))\n",
    "new_user_ratings_df = new_user_ratings_df.withColumn('movieId', new_user_ratings_df[1].cast(IntegerType()))\n",
    "new_user_ratings_df = new_user_ratings_df.withColumn('rating', new_user_ratings_df[2].cast(FloatType()))\n",
    "\n",
    "# removing irrelevant data from new_user_ratings_df\n",
    "new_user_ratings_df = new_user_ratings_df.selectExpr(\"userId\",\"movieId\",\"rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   4.0|\n",
      "|     1|      1|   3.0|\n",
      "|     1|     16|   2.0|\n",
      "|     1|     25|   3.0|\n",
      "|     1|     32|   4.0|\n",
      "|     1|    335|   4.0|\n",
      "|     1|    379|   3.0|\n",
      "|     1|    296|   2.0|\n",
      "|     1|    858|   5.0|\n",
      "|     1|     50|   3.0|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[userId: int, movieId: int, rating: float]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensuring that new_user_ratings_df loaded correctly and checking schema\n",
    "new_user_ratings_df.show()\n",
    "new_user_ratings_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE NEW USER RATINGS WITH THE COMPLETE RATINGS\n",
    "complete_data_with_new_ratings_df = complete_ratings_df.union(new_user_ratings_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n",
      "100846\n"
     ]
    }
   ],
   "source": [
    "print(complete_ratings_df.count())\n",
    "print(complete_data_with_new_ratings_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100846"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking that new_user_ratings added correctly\n",
    "#N.B recall that number of rating was less than this number by 10 ...\n",
    "complete_data_with_new_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complete_data_with_new_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 1.777 seconds\n"
     ]
    }
   ],
   "source": [
    "# TRAIN NEW MODEL WITH NEW ADDED DATA \n",
    "t0 = time()\n",
    "als = ALS(maxIter=best_iterations, regParam=best_regParm,rank=best_rank, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
    "new_ratings_model = als.fit(complete_data_with_new_ratings_df)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in {} seconds\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking invalid predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting new rated movies into a list \n",
    "invalid_predictions = list(map(lambda x: x[1], new_user_ratings))\n",
    "# extracting user_id from new_user_ratings_df\n",
    "user_id=new_user_ratings_df.select('userId').take(1)[0]['userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 16, 25, 32, 335, 379, 296, 858, 50]\n"
     ]
    }
   ],
   "source": [
    "#print pre-rated movies (invalid)\n",
    "print(invalid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_movies_df \n",
    "new_movies_df=complete_movies_df.filter(~complete_movies_df['movieId'].isin(invalid_predictions)).withColumn('userId', lit(user_id)).drop('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|movieId|\n",
      "+------+-------+\n",
      "|     1|      3|\n",
      "|     1|      4|\n",
      "|     1|      5|\n",
      "|     1|      6|\n",
      "|     1|      7|\n",
      "|     1|      8|\n",
      "|     1|      9|\n",
      "|     1|     10|\n",
      "|     1|     11|\n",
      "|     1|     12|\n",
      "|     1|     13|\n",
      "|     1|     14|\n",
      "|     1|     15|\n",
      "|     1|     17|\n",
      "|     1|     18|\n",
      "|     1|     19|\n",
      "|     1|     20|\n",
      "|     1|     21|\n",
      "|     1|     22|\n",
      "|     1|     23|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print new_movies_df (this dataframe should be all from valid movies)\n",
    "new_movies_df=new_movies_df.select('userId', 'movieId').cache()\n",
    "new_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|movieId|\n",
      "+------+-------+\n",
      "|     1|      3|\n",
      "|     1|      4|\n",
      "|     1|      5|\n",
      "|     1|      6|\n",
      "|     1|      7|\n",
      "|     1|      8|\n",
      "|     1|      9|\n",
      "|     1|     10|\n",
      "|     1|     11|\n",
      "|     1|     12|\n",
      "|     1|     13|\n",
      "|     1|     14|\n",
      "|     1|     15|\n",
      "|     1|     17|\n",
      "|     1|     18|\n",
      "|     1|     19|\n",
      "|     1|     20|\n",
      "|     1|     21|\n",
      "|     1|     22|\n",
      "|     1|     23|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- movieId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_movies_df.show()\n",
    "new_movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[-0.5427709, 0.29...|\n",
      "| 20|[-0.16825935, -0....|\n",
      "| 30|[-0.3532909, -0.2...|\n",
      "| 40|[-0.72978, 0.0269...|\n",
      "| 50|[-0.26852262, 0.0...|\n",
      "| 60|[-0.4512421, -0.1...|\n",
      "| 70|[-0.4393683, -0.0...|\n",
      "| 80|[-0.61166096, 0.0...|\n",
      "| 90|[-0.46840835, 0.0...|\n",
      "|100|[-0.5718834, -0.1...|\n",
      "|110|[-0.31890944, 0.1...|\n",
      "|120|[-0.48787358, -0....|\n",
      "|130|[-0.49742514, -0....|\n",
      "|140|[-0.54451835, 0.0...|\n",
      "|150|[-0.5248455, -0.0...|\n",
      "|160|[-0.37851775, 0.5...|\n",
      "|170|[-0.40053913, -0....|\n",
      "|180|[-0.4262179, 0.06...|\n",
      "|190|[-0.33076447, -0....|\n",
      "|200|[-0.35692716, -0....|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_ratings_model.userFactors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|movieId|prediction|\n",
      "+------+-------+----------+\n",
      "|     1|    148| 4.3434587|\n",
      "|     1|    471|  4.290055|\n",
      "|     1|    496| 4.3434587|\n",
      "|     1|    833| 2.1454613|\n",
      "|     1|   1088| 3.7730947|\n",
      "|     1|   1238|  4.607239|\n",
      "|     1|   1342|  3.102829|\n",
      "|     1|   1580| 4.0160565|\n",
      "|     1|   1591| 3.0741577|\n",
      "|     1|   1645| 3.8810644|\n",
      "|     1|   1829| 3.8038137|\n",
      "|     1|   1959| 4.3276644|\n",
      "|     1|   2122| 3.0483038|\n",
      "|     1|   2142| 3.4739676|\n",
      "|     1|   2366|  3.997889|\n",
      "|     1|   2659|  2.011827|\n",
      "|     1|   2866| 3.7860649|\n",
      "|     1|   3175|  4.028168|\n",
      "|     1|   3794| 2.9218812|\n",
      "|     1|   3918| 3.7580264|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# finding new user recommendations \n",
    "new_user_recommendations_df = bestmodel.transform(new_movies_df)\n",
    "new_user_recommendations_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joing new_user_recommendations_df with movies_rating_counts_df in order in order to recommend the highly rated movies\n",
    "new_user_rating_recommendation_df =new_user_recommendations_df.join(movies_rating_counts_df, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 25 moveis recommended for user \n",
    "top_movies=new_user_rating_recommendation_df[(new_user_rating_recommendation_df['count'] >= 25)].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=471, userId=1, prediction=4.290054798126221, count=40),\n",
       " Row(movieId=1088, userId=1, prediction=3.773094654083252, count=42),\n",
       " Row(movieId=1580, userId=1, prediction=4.016056537628174, count=165),\n",
       " Row(movieId=1591, userId=1, prediction=3.07415771484375, count=26),\n",
       " Row(movieId=1645, userId=1, prediction=3.8810644149780273, count=51),\n",
       " Row(movieId=2366, userId=1, prediction=3.9978890419006348, count=25),\n",
       " Row(movieId=3175, userId=1, prediction=4.028168201446533, count=75),\n",
       " Row(movieId=1025, userId=1, prediction=4.284240245819092, count=25),\n",
       " Row(movieId=1084, userId=1, prediction=4.723385810852051, count=35),\n",
       " Row(movieId=1127, userId=1, prediction=4.0520405769348145, count=62),\n",
       " Row(movieId=1721, userId=1, prediction=3.7387449741363525, count=140),\n",
       " Row(movieId=2580, userId=1, prediction=4.54417085647583, count=39),\n",
       " Row(movieId=3698, userId=1, prediction=3.9495725631713867, count=34),\n",
       " Row(movieId=48780, userId=1, prediction=4.631921768188477, count=90),\n",
       " Row(movieId=69481, userId=1, prediction=4.548560619354248, count=34),\n",
       " Row(movieId=31, userId=1, prediction=3.707376718521118, count=38),\n",
       " Row(movieId=1270, userId=1, prediction=4.629855632781982, count=171),\n",
       " Row(movieId=1339, userId=1, prediction=4.009859561920166, count=29),\n",
       " Row(movieId=2393, userId=1, prediction=3.4648425579071045, count=33),\n",
       " Row(movieId=2572, userId=1, prediction=4.0737409591674805, count=54),\n",
       " Row(movieId=3000, userId=1, prediction=4.571955680847168, count=48),\n",
       " Row(movieId=82459, userId=1, prediction=4.39393424987793, count=28),\n",
       " Row(movieId=1265, userId=1, prediction=4.67324161529541, count=143),\n",
       " Row(movieId=1884, userId=1, prediction=4.352607727050781, count=46),\n",
       " Row(movieId=2231, userId=1, prediction=4.62476921081543, count=36)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prining Top 25 moveis recommended for user \n",
    "top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
